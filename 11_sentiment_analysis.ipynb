{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "noticed-imaging",
   "metadata": {},
   "source": [
    "# Performing Sentiment Analysis on Text Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "median-pledge",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>overall</th>\n",
       "      <th>verified</th>\n",
       "      <th>reviewTime</th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>asin</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>summary</th>\n",
       "      <th>unixReviewTime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>86841</th>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>05 23, 2015</td>\n",
       "      <td>A2W1XFPQPJFMRI</td>\n",
       "      <td>B0009JMW1C</td>\n",
       "      <td>Didn't do anything for me</td>\n",
       "      <td>One Star</td>\n",
       "      <td>1432339200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89784</th>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>06 6, 2017</td>\n",
       "      <td>A3Q0RNCFOMFA1A</td>\n",
       "      <td>B001ASC022</td>\n",
       "      <td>The taste didn't do anything for me</td>\n",
       "      <td>Two Stars</td>\n",
       "      <td>1496707200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115834</th>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>09 22, 2014</td>\n",
       "      <td>A120QLSB8F9LRW</td>\n",
       "      <td>B00CGSF5A4</td>\n",
       "      <td>RETURNED</td>\n",
       "      <td>Two Stars</td>\n",
       "      <td>1411344000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72339</th>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>01 28, 2017</td>\n",
       "      <td>A1LMMPPG9NCNWH</td>\n",
       "      <td>B013VTS40E</td>\n",
       "      <td>I lose the cellphone signal</td>\n",
       "      <td>Two Stars</td>\n",
       "      <td>1485561600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>271537</th>\n",
       "      <td>5</td>\n",
       "      <td>True</td>\n",
       "      <td>03 23, 2016</td>\n",
       "      <td>ALTD6YE7J2AKU</td>\n",
       "      <td>B007BRGT6Y</td>\n",
       "      <td>Worked great, no complaints.</td>\n",
       "      <td>Good product</td>\n",
       "      <td>1458691200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        overall  verified   reviewTime      reviewerID        asin  \\\n",
       "86841         1      True  05 23, 2015  A2W1XFPQPJFMRI  B0009JMW1C   \n",
       "89784         2      True   06 6, 2017  A3Q0RNCFOMFA1A  B001ASC022   \n",
       "115834        2      True  09 22, 2014  A120QLSB8F9LRW  B00CGSF5A4   \n",
       "72339         2      True  01 28, 2017  A1LMMPPG9NCNWH  B013VTS40E   \n",
       "271537        5      True  03 23, 2016   ALTD6YE7J2AKU  B007BRGT6Y   \n",
       "\n",
       "                                 reviewText       summary  unixReviewTime  \n",
       "86841             Didn't do anything for me      One Star      1432339200  \n",
       "89784   The taste didn't do anything for me     Two Stars      1496707200  \n",
       "115834                             RETURNED     Two Stars      1411344000  \n",
       "72339           I lose the cellphone signal     Two Stars      1485561600  \n",
       "271537         Worked great, no complaints.  Good product      1458691200  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_json(\"data/reviews_5_balanced.json.gz\", lines=True)\n",
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "nervous-ethics",
   "metadata": {},
   "source": [
    "### Blueprint: Performing Sentiment Analysis using Lexicon-Based approaches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "therapeutic-department",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package opinion_lexicon to\n",
      "[nltk_data]     /Users/alextanhongpin/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/opinion_lexicon.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import opinion_lexicon\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "nltk.download(\"opinion_lexicon\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "molecular-volleyball",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of words in opinion lexicon 6789\n",
      "Examples of positive words in opinion lexicon ['a+', 'abound', 'abounds', 'abundance', 'abundant']\n",
      "Examples of negative words in opinion lexicon ['2-faced', '2-faces', 'abnormal', 'abolish', 'abominable']\n"
     ]
    }
   ],
   "source": [
    "print(\"Total number of words in opinion lexicon\", len(opinion_lexicon.words()))\n",
    "print(\"Examples of positive words in opinion lexicon\", opinion_lexicon.positive()[:5])\n",
    "print(\"Examples of negative words in opinion lexicon\", opinion_lexicon.negative()[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "successful-pepper",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rename(columns={\"reviewText\": \"text\"}, inplace=True)\n",
    "pos_score = 1\n",
    "neg_score = -1\n",
    "word_dict = {}\n",
    "\n",
    "# Adding the positive words to the dictionary.\n",
    "for word in opinion_lexicon.positive():\n",
    "    word_dict[word] = pos_score\n",
    "\n",
    "# Adding the negative words to the dictionary.\n",
    "for word in opinion_lexicon.negative():\n",
    "    word_dict[word] = neg_score\n",
    "\n",
    "\n",
    "def bing_liu_score(text):\n",
    "    sentiment_score = 0\n",
    "    bag_of_words = word_tokenize(text.lower())\n",
    "\n",
    "    for word in bag_of_words:\n",
    "        if word in word_dict:\n",
    "            sentiment_score += word_dict[word]\n",
    "    return sentiment_score / len(bag_of_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ignored-firmware",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>asin</th>\n",
       "      <th>text</th>\n",
       "      <th>bing_liu_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>192836</th>\n",
       "      <td>B005UQSV3W</td>\n",
       "      <td>ok</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70036</th>\n",
       "      <td>B00YG8MLOA</td>\n",
       "      <td>It broke the first time I used it.</td>\n",
       "      <td>-0.111111</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              asin                                text  bing_liu_score\n",
       "192836  B005UQSV3W                                  ok        0.000000\n",
       "70036   B00YG8MLOA  It broke the first time I used it.       -0.111111"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"bing_liu_score\"] = df[\"text\"].apply(bing_liu_score)\n",
    "df[[\"asin\", \"text\", \"bing_liu_score\"]].sample(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "numerical-backup",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bing_liu_score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>overall</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.049764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.000157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.238446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.295418</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         bing_liu_score\n",
       "overall                \n",
       "1             -0.049764\n",
       "2             -0.000157\n",
       "4              0.238446\n",
       "5              0.295418"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "\n",
    "df[[\"bing_liu_score\"]] = scaler.fit_transform(df[[\"bing_liu_score\"]])\n",
    "df.groupby(\"overall\").agg({\"bing_liu_score\": \"mean\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "united-intranet",
   "metadata": {},
   "source": [
    "## Supervised Learning Approaches"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "spare-memorabilia",
   "metadata": {},
   "source": [
    "### Preparing Data for a Supervised Learning Approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "excellent-taiwan",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>verified</th>\n",
       "      <th>asin</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>160475</th>\n",
       "      <td>True</td>\n",
       "      <td>B00OL1UWCK</td>\n",
       "      <td>Another TH product that I love.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185989</th>\n",
       "      <td>True</td>\n",
       "      <td>B0002Q80GS</td>\n",
       "      <td>Easy to install on my Honda RL</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116814</th>\n",
       "      <td>True</td>\n",
       "      <td>B00JJAI5GS</td>\n",
       "      <td>Battery died in the remote.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        verified        asin                       reviewText  sentiment\n",
       "160475      True  B00OL1UWCK  Another TH product that I love.          1\n",
       "185989      True  B0002Q80GS   Easy to install on my Honda RL          1\n",
       "116814      True  B00JJAI5GS      Battery died in the remote.          0"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_json(\"data/reviews_5_balanced.json.gz\", lines=True)\n",
    "\n",
    "# Assigning a new [1, 0] target class label based on the product rating.\n",
    "df[\"sentiment\"] = 0\n",
    "df.loc[df[\"overall\"] > 3, \"sentiment\"] = 1\n",
    "df.loc[df[\"overall\"] < 3, \"sentiment\"] = 0\n",
    "\n",
    "# Removing unnecessary columns to keep a simple DataFrame.\n",
    "df.drop(\n",
    "    columns=[\"reviewTime\", \"unixReviewTime\", \"overall\", \"reviewerID\", \"summary\"],\n",
    "    inplace=True,\n",
    ")\n",
    "df.sample(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "breeding-enough",
   "metadata": {},
   "source": [
    "### Blueprint: Vectorizing Text Data and Applying a Supervised Machine Learning Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "consecutive-haven",
   "metadata": {},
   "source": [
    "**Step 1: Data Preparation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "twelve-admission",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run preprocess.py\n",
    "%run spacy_preprocess.py\n",
    "\n",
    "df.rename(columns={\"reviewText\": \"text\"}, inplace=True)\n",
    "df[\"text_orig\"] = df[\"text\"].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "likely-experiment",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb4a212b687143518428f59ac3d5f6e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/294240 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "\n",
    "df[\"text\"] = df[\"text\"].apply(clean)\n",
    "\n",
    "clean = []\n",
    "for doc in tqdm(nlp.pipe(df[\"text\"].values), total=len(df[\"text\"])):\n",
    "    # From Blueprint function\n",
    "    lemmas = extract_lemmas(\n",
    "        doc,\n",
    "        exclude_pos=[\"PART\", \"PUNCT\", \"DET\", \"PRON\", \"SYM\", \"SPACE\", \"NUM\"],\n",
    "        filter_stops=True,\n",
    "        filter_nums=True,\n",
    "        filter_punct=True,\n",
    "    )\n",
    "    clean.append(lemmas)\n",
    "\n",
    "df[\"text\"] = clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "remarkable-catalog",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove observations that are empty after the cleaning step.\n",
    "df = df[df[\"text\"].str.len() != 0]\n",
    "df[\"text\"] = df[\"text\"].map(lambda x: \" \".join(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "simplified-belfast",
   "metadata": {},
   "source": [
    "**Step 2: Train-Test Split**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "sacred-donna",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of training data 233966\n",
      "Size of test data 58492\n",
      "Distribution of classes in training data:\n",
      "Positive sentiment 51.00612909568056\n",
      "Negative sentiment 48.99387090431943\n",
      "Distribution of classes in testing data:\n",
      "Positive sentiment 51.00526567735759\n",
      "Negative sentiment 48.994734322642415\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df[\"text\"],\n",
    "    df[\"sentiment\"],\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=df[\"sentiment\"],\n",
    ")\n",
    "\n",
    "print(\"Size of training data\", X_train.shape[0])\n",
    "print(\"Size of test data\", X_test.shape[0])\n",
    "\n",
    "print(\"Distribution of classes in training data:\")\n",
    "print(\"Positive sentiment\", str(sum(y_train == 1) / len(y_train) * 100.0))\n",
    "print(\"Negative sentiment\", str(sum(y_train == 0) / len(y_train) * 100.0))\n",
    "\n",
    "print(\"Distribution of classes in testing data:\")\n",
    "print(\"Positive sentiment\", str(sum(y_test == 1) / len(y_test) * 100.0))\n",
    "print(\"Negative sentiment\", str(sum(y_test == 0) / len(y_test) * 100.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caroline-marking",
   "metadata": {},
   "source": [
    "**Step 3: Text Vectorization**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "sized-consent",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "laughing-kitty",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer(min_df=10, ngram_range=(1, 1))\n",
    "X_train_tf = tfidf.fit_transform(X_train)\n",
    "X_test_tf = tfidf.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "affiliated-pearl",
   "metadata": {},
   "source": [
    "**Step 4: Training the Machine Learning Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "powered-beginning",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearSVC(random_state=42, tol=1e-05)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "model1 = LinearSVC(random_state=42, tol=1e-5)\n",
    "model1.fit(X_train_tf, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "nearby-sugar",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score - 0.8553477398618614\n",
      "ROC-AUC score - 0.8557214846429678\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "\n",
    "y_pred = model1.predict(X_test_tf)\n",
    "print(\"Accuracy score -\", accuracy_score(y_test, y_pred))\n",
    "print(\"ROC-AUC score -\", roc_auc_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "moral-criticism",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Some sample reviews with their sentiment - \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_orig</th>\n",
       "      <th>sentiment_prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>22683</th>\n",
       "      <td>I don't know about the LINT FREE thingie, this...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122239</th>\n",
       "      <td>squirrels too nclever</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>273909</th>\n",
       "      <td>looks good on my DRZ</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159790</th>\n",
       "      <td>Just as I expected.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110018</th>\n",
       "      <td>Um... go with a MXR instead</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text_orig  \\\n",
       "22683   I don't know about the LINT FREE thingie, this...   \n",
       "122239                              squirrels too nclever   \n",
       "273909                               looks good on my DRZ   \n",
       "159790                                Just as I expected.   \n",
       "110018                        Um... go with a MXR instead   \n",
       "\n",
       "        sentiment_prediction  \n",
       "22683                      0  \n",
       "122239                     0  \n",
       "273909                     1  \n",
       "159790                     1  \n",
       "110018                     0  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_reviews = df.sample(5)\n",
    "sample_reviews_tf = tfidf.transform(sample_reviews[\"text\"])\n",
    "sentiment_predictions = model1.predict(sample_reviews_tf)\n",
    "sentiment_predictions = pd.DataFrame(\n",
    "    data=sentiment_predictions,\n",
    "    index=sample_reviews.index,\n",
    "    columns=[\"sentiment_prediction\"],\n",
    ")\n",
    "sample_reviews = pd.concat([sample_reviews, sentiment_predictions], axis=1)\n",
    "print(\"Some sample reviews with their sentiment - \")\n",
    "sample_reviews[[\"text_orig\", \"sentiment_prediction\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "powered-blocking",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7571462764138686"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def baseline_score(text):\n",
    "    score = bing_liu_score(text)\n",
    "    if score > 0:\n",
    "        return 1\n",
    "    return 0\n",
    "\n",
    "\n",
    "y_pred_baseline = X_test.apply(baseline_score)\n",
    "acc_score = accuracy_score(y_pred_baseline, y_test)\n",
    "acc_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cubic-status",
   "metadata": {},
   "source": [
    "## Pretrained Language Models using Deep Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "first-journalist",
   "metadata": {},
   "source": [
    "**Step 1: Loading Models and Tokenization**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "perceived-parts",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "varied-thumbnail",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertConfig, BertForSequenceClassification, BertTokenizer\n",
    "\n",
    "config = BertConfig.from_pretrained(\"bert-base-uncased\", finetuning_task=\"binary\")\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "humanitarian-express",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tokens(text, tokenizer, max_seq_length, add_special_tokens=True):\n",
    "    input_ids = tokenizer.encode(\n",
    "        text,\n",
    "        add_special_tokens=add_special_tokens,\n",
    "        max_length=max_seq_length,\n",
    "        padding=\"max_length\",\n",
    "        truncation=True,\n",
    "    )\n",
    "    attention_mask = [int(id > 0) for id in input_ids]\n",
    "    assert len(input_ids) == max_seq_length\n",
    "    assert len(attention_mask) == max_seq_length\n",
    "    return (input_ids, attention_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "vital-rescue",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here is the sentence I want embeddings for.\n",
      "['[CLS]', 'here', 'is', 'the', 'sentence', 'i', 'want', 'em', '##bed', '##ding', '##s', 'for', '.', '[SEP]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]']\n",
      "[101, 2182, 2003, 1996, 6251, 1045, 2215, 7861, 8270, 4667, 2015, 2005, 1012, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "text = \"Here is the sentence I want embeddings for.\"\n",
    "input_ids, attention_mask = get_tokens(\n",
    "    text, tokenizer, max_seq_length=30, add_special_tokens=True\n",
    ")\n",
    "input_tokens = tokenizer.convert_ids_to_tokens(input_ids)\n",
    "\n",
    "print(text)\n",
    "print(input_tokens)\n",
    "print(input_ids)\n",
    "print(attention_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "julian-onion",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/transformers/tokenization_utils_base.py:2271: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df[\"text_orig\"],\n",
    "    df[\"sentiment\"],\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=df[\"sentiment\"],\n",
    ")\n",
    "X_train_tokens = X_train.apply(get_tokens, args=(tokenizer, 50))\n",
    "X_test_tokens = X_test.apply(get_tokens, args=(tokenizer, 50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "registered-seeking",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "biological-singapore",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([233966, 50])\n",
      "torch.Size([233966, 50])\n",
      "torch.Size([233966])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import TensorDataset\n",
    "\n",
    "input_ids_train = torch.tensor(\n",
    "    [features[0] for features in X_train_tokens.values], dtype=torch.long\n",
    ")\n",
    "input_mask_train = torch.tensor(\n",
    "    [features[1] for features in X_train_tokens.values], dtype=torch.long\n",
    ")\n",
    "label_ids_train = torch.tensor(y_train.values, dtype=torch.long)\n",
    "\n",
    "print(input_ids_train.shape)\n",
    "print(input_mask_train.shape)\n",
    "print(label_ids_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "wicked-freight",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([  101,  1045,  2001,  2409,  2011, 29237, 27082,  8013,  2326,  2008,\n",
       "         1045,  2071,  3202,  2404,  2091,  5568,  6534,  1999,  1996,  6436,\n",
       "         7516,  2073,  1996, 15289, 27082,  2001, 25401,  1010,  2021,  6854,\n",
       "         2025,  2028,  6534,  1997,  5568,  2412, 16216, 27512,  4383,  1012,\n",
       "          102,     0,     0,     0,     0,     0,     0,     0,     0,     0])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_ids_train[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "unique-cholesterol",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = TensorDataset(input_ids_train, input_mask_train, label_ids_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "serious-missile",
   "metadata": {},
   "source": [
    "**Step 2: Model Training**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "patient-china",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number examples = 233966\n",
      "Num epochs = 2\n",
      "Total train batch size = 64\n",
      "Total optimization steps = 1828\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader, RandomSampler\n",
    "\n",
    "train_batch_size = 64\n",
    "num_train_epochs = 2\n",
    "\n",
    "train_sampler = RandomSampler(train_dataset)\n",
    "train_dataloader = DataLoader(\n",
    "    train_dataset, sampler=train_sampler, batch_size=train_batch_size\n",
    ")\n",
    "\n",
    "t_total = len(train_dataloader) // num_train_epochs\n",
    "\n",
    "print(\"Number examples =\", len(train_dataset))\n",
    "print(\"Num epochs =\", num_train_epochs)\n",
    "print(\"Total train batch size =\", train_batch_size)\n",
    "print(\"Total optimization steps =\", t_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "continental-infection",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import AdamW\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "\n",
    "learning_rate = 1e-4\n",
    "adam_epsilon = 1e-8\n",
    "warmup_steps = 0\n",
    "\n",
    "optimizer = AdamW(model.parameters(), lr=learning_rate, eps=adam_epsilon)\n",
    "scheduler = get_linear_schedule_with_warmup(\n",
    "    optimizer, num_warmup_steps=warmup_steps, num_training_steps=t_total\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "unnecessary-norwegian",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:   0%|                                                                                                                     | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1035f61c8b834de990bab7827e476e4a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/3656 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6643181443214417"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:   0%|                                                                                                                     | 0/2 [02:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [63]\u001b[0m, in \u001b[0;36m<cell line: 9>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\r\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mloss\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, end\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     31\u001b[0m \u001b[38;5;66;03m# Back-propagate the loss (automatically calculates gradients).\u001b[39;00m\n\u001b[0;32m---> 32\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;66;03m# Prevent exploding gradients by limiting gradients to 1.0\u001b[39;00m\n\u001b[1;32m     35\u001b[0m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mclip_grad_norm_(model\u001b[38;5;241m.\u001b[39mparameters(), \u001b[38;5;241m1.0\u001b[39m)\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/site-packages/torch/_tensor.py:307\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    298\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    299\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    300\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    301\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    305\u001b[0m         create_graph\u001b[38;5;241m=\u001b[39mcreate_graph,\n\u001b[1;32m    306\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs)\n\u001b[0;32m--> 307\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/site-packages/torch/autograd/__init__.py:154\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m retain_graph \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    152\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[0;32m--> 154\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    155\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    156\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from tqdm import notebook, trange\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "train_iterator = trange(num_train_epochs, desc=\"Epoch\")\n",
    "\n",
    "# Put model in 'train' mode.\n",
    "model.train()\n",
    "\n",
    "for epoch in train_iterator:\n",
    "    epoch_iterator = notebook.tqdm(train_dataloader, desc=\"Iteration\")\n",
    "    for step, batch in enumerate(epoch_iterator):\n",
    "        # Reset all gradients at start of every iteration.\n",
    "        model.zero_grad()\n",
    "\n",
    "        # Put the model and the input observations to GPU.\n",
    "        model.to(device)\n",
    "\n",
    "        batch = tuple(t.to(device) for t in batch)\n",
    "\n",
    "        # Identify the inputs to the model.\n",
    "        inputs = {\"input_ids\": batch[0], \"attention_mask\": batch[1], \"labels\": batch[2]}\n",
    "\n",
    "        # Forward pass through the model. Input -> Model -> Output.\n",
    "        outputs = model(**inputs)\n",
    "\n",
    "        # Determine the deviation (loss).\n",
    "        loss = outputs[0]\n",
    "\n",
    "        print(f\"\\r{loss}\", end=\"\")\n",
    "\n",
    "        # Back-propagate the loss (automatically calculates gradients).\n",
    "        loss.backward()\n",
    "\n",
    "        # Prevent exploding gradients by limiting gradients to 1.0\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "\n",
    "        # Update the parameters and learning rate.\n",
    "        optimizer.step()\n",
    "        scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "geographic-brighton",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_pretrained(\"outputs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "copyrighted-shanghai",
   "metadata": {},
   "source": [
    "**Step 3: Model Evaluation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "occupational-local",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from torch.utils.data import SequentialSampler\n",
    "\n",
    "test_batch_size = 64\n",
    "test_sampler = SequentialSampler(test_dataset)\n",
    "test_dataloader = DataLoader(\n",
    "    test_dataset, sampler=test_sampler, batch_size=test_batch_size\n",
    ")\n",
    "\n",
    "# Load the pretrained model that was saved earlier.\n",
    "model = model.from_pretrained(\"/outputs\")\n",
    "\n",
    "\n",
    "# Initialize the prediction and actual labels.\n",
    "preds = None\n",
    "out_label_ids = None\n",
    "\n",
    "# Put model in \"eval\" mode.\n",
    "model.eval()\n",
    "\n",
    "for batch in notebook.tqdm(test_dataloader, desc=\"Evaluating\"):\n",
    "    # Put the model and the input observations to GPU.\n",
    "    model.to(device)\n",
    "    batch = tuple(t.to(device) for t in batch)\n",
    "\n",
    "    # Do not track any gradients since in 'eval' mode.\n",
    "    with torch.no_grad():\n",
    "        inputs = {\"input_ids\": batch[0], \"attention_mask\": batch[1], \"labels\": batch[2]}\n",
    "\n",
    "        # Forward pass through the model.\n",
    "        outputs = model(**inputs)\n",
    "\n",
    "        # We get loss since we provided the labels.\n",
    "        tmp_eval_loss, logits = outputs[:2]\n",
    "\n",
    "        # There maybe more than one batch of items in the test dataset.\n",
    "        if preds is None:\n",
    "            preds = logits.detach().cpu().numpy()\n",
    "            out_label_ids = inputs[\"labels\"].detach().cpu().numpy()\n",
    "\n",
    "        else:\n",
    "            preds = np.append(preds, logits.detach().cpu().numpy(), axis=0)\n",
    "            out_label_ids = np.append(\n",
    "                out_label_ids, inputs[\"labels\"].detach().cpu().numpy(), axis=0\n",
    "            )\n",
    "            \n",
    "# Get final loss, predictions and accuracy.\n",
    "preds= np.argmax(preds, axis=1)\n",
    "acc_score = accuracy_score(preds, out_label_ids)\n",
    "print('Accuracy Score on test data', acc_score)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
