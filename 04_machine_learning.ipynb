{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "instructional-advice",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "statistical-orchestra",
   "metadata": {},
   "outputs": [],
   "source": [
    "posts_file = \"data/rspct_autos.tsv\"\n",
    "posts_df = pd.read_csv(posts_file, sep=\"\\t\")\n",
    "\n",
    "subred_file = \"data/subreddit_info.csv.gz\"\n",
    "subred_df = pd.read_csv(subred_file).set_index([\"subreddit\"])\n",
    "\n",
    "df = posts_df.join(subred_df, on=\"subreddit\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "meaning-dining",
   "metadata": {},
   "source": [
    "### Blueprint: Standardizing Attribute Names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "widespread-milton",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'subreddit', 'title', 'selftext', 'category_1', 'category_2',\n",
       "       'category_3', 'in_data', 'reason_for_exclusion'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "secure-rebate",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>8020</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <td>63wxeo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>subreddit</th>\n",
       "      <td>mazda3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>title</th>\n",
       "      <td>Blew my motor :(</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>text</th>\n",
       "      <td>my 08 hatch spun a rod bearing the other day a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>category</th>\n",
       "      <td>autos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>subcategory</th>\n",
       "      <td>mazda</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                          8020\n",
       "id                                                      63wxeo\n",
       "subreddit                                               mazda3\n",
       "title                                         Blew my motor :(\n",
       "text         my 08 hatch spun a rod bearing the other day a...\n",
       "category                                                 autos\n",
       "subcategory                                              mazda"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "column_mapping = {\n",
    "    \"id\": \"id\",\n",
    "    \"subreddit\": \"subreddit\",\n",
    "    \"title\": \"title\",\n",
    "    \"selftext\": \"text\",\n",
    "    \"category_1\": \"category\",\n",
    "    \"category_2\": \"subcategory\",\n",
    "    \"category_3\": None,  # No data.\n",
    "    \"in_data\": None,  # Not needed.\n",
    "    \"reason_for_exclusion\": None,  # Not needed.\n",
    "}\n",
    "\n",
    "# Define remaining columns.\n",
    "columns = [c for c in column_mapping.keys() if column_mapping[c] != None]\n",
    "\n",
    "# Select and rename those columns.\n",
    "df = df[columns].rename(columns=column_mapping)\n",
    "\n",
    "# Limit the data to autos category.\n",
    "df = df[df[\"category\"] == \"autos\"]\n",
    "df.sample(1).T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abstract-afghanistan",
   "metadata": {},
   "source": [
    "**Saving and loading a Dataframe**\n",
    "\n",
    "Storing in SQL has more advantages over pickle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "loaded-cutting",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.to_pickle('reddit_dataframe.pkl')\n",
    "\n",
    "import sqlite3\n",
    "\n",
    "db_name = \"reddit-selfposts.db\"\n",
    "con = sqlite3.connect(db_name)\n",
    "df.to_sql(\"posts\", con, index=False, if_exists=\"replace\")\n",
    "con.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ordinary-flash",
   "metadata": {},
   "outputs": [],
   "source": [
    "con = sqlite3.connect(db_name)\n",
    "df = pd.read_sql(\"select * from posts\", con)\n",
    "con.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "angry-cruise",
   "metadata": {},
   "source": [
    "## Cleaning Text Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "likely-beach",
   "metadata": {},
   "source": [
    "### Blueprint: Identify Noise with Regular Expressions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "egyptian-phone",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.08438818565400844"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "RE_SUSPICIOUS = re.compile(r\"[&#<>{}\\[\\]\\\\]\")\n",
    "\n",
    "\n",
    "def impurity(text, min_len=10):\n",
    "    \"\"\"Returns the share of suspicious characters in a text.\"\"\"\n",
    "    if text == None or len(text) < min_len:\n",
    "        return 0\n",
    "    else:\n",
    "        return len(RE_SUSPICIOUS.findall(text)) / len(text)\n",
    "\n",
    "\n",
    "text = \"\"\"\n",
    "After viewing the [PINKIEPOOL Trailer](https://www.youtu.be/watch?v=ieHRoHUg)     \n",
    "it got me thinking about the best match ups.     \n",
    "<lb>Here's my take:<lb><lb>[](/sp)[](/ppseesyou) Deadpool<lb>[](/sp)[](/ajsly)     \n",
    "Captain America<lb>\"\"\"\n",
    "\n",
    "impurity(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fundamental-animal",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>impurity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19682</th>\n",
       "      <td>Looking at buying a 335i with 39k miles and 11...</td>\n",
       "      <td>0.214716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12357</th>\n",
       "      <td>I'm looking to lease an a4 premium plus automa...</td>\n",
       "      <td>0.165099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2730</th>\n",
       "      <td>Breakdown below:&lt;lb&gt;&lt;lb&gt;Elantra GT&lt;lb&gt;&lt;lb&gt;2.0L...</td>\n",
       "      <td>0.139130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12754</th>\n",
       "      <td>Bulbs Needed:&lt;lb&gt;&lt;lb&gt;&lt;lb&gt;**194 LED BULB x8**&lt;l...</td>\n",
       "      <td>0.132411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10726</th>\n",
       "      <td>I currently have a deposit on a 2013 335is (CP...</td>\n",
       "      <td>0.129317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15867</th>\n",
       "      <td>All the wash places around me are very expensi...</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8311</th>\n",
       "      <td>I've recently been having some issues with my ...</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15865</th>\n",
       "      <td>My 2006 9-3 has gone into limp home mode and I...</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15864</th>\n",
       "      <td>I'm currently looking at cars (online) and I c...</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10000</th>\n",
       "      <td>Well so, it was the 80s and 90s. Icelandic pol...</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  impurity\n",
       "19682  Looking at buying a 335i with 39k miles and 11...  0.214716\n",
       "12357  I'm looking to lease an a4 premium plus automa...  0.165099\n",
       "2730   Breakdown below:<lb><lb>Elantra GT<lb><lb>2.0L...  0.139130\n",
       "12754  Bulbs Needed:<lb><lb><lb>**194 LED BULB x8**<l...  0.132411\n",
       "10726  I currently have a deposit on a 2013 335is (CP...  0.129317\n",
       "...                                                  ...       ...\n",
       "15867  All the wash places around me are very expensi...  0.000000\n",
       "8311   I've recently been having some issues with my ...  0.000000\n",
       "15865  My 2006 9-3 has gone into limp home mode and I...  0.000000\n",
       "15864  I'm currently looking at cars (online) and I c...  0.000000\n",
       "10000  Well so, it was the 80s and 90s. Icelandic pol...  0.000000\n",
       "\n",
       "[20000 rows x 2 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add new column to data frame.\n",
    "df[\"impurity\"] = df[\"text\"].apply(impurity, min_len=10)\n",
    "\n",
    "# Get the top 3 records.\n",
    "df[[\"text\", \"impurity\"]].sort_values(by=\"impurity\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "virtual-chapel",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run exploration.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "hungry-origin",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>freq</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>token</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>&lt;lb&gt;</th>\n",
       "      <td>100729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>&lt;tab&gt;</th>\n",
       "      <td>642</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         freq\n",
       "token        \n",
       "<lb>   100729\n",
       "<tab>     642"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_words(df, column=\"text\", preprocess=lambda t: re.findall(r\"<[\\w/]*>\", t))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "instrumental-secretary",
   "metadata": {},
   "source": [
    "### Blueprint: Removing Noise with Regular Expressions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "temporal-polymer",
   "metadata": {},
   "outputs": [],
   "source": [
    "import html\n",
    "\n",
    "\n",
    "def clean(text):\n",
    "    # convert html escapes like &amp; to characters.\n",
    "    text = html.unescape(text)\n",
    "\n",
    "    # tags like <tab>\n",
    "    text = re.sub(r\"<[^<>]*>\", \" \", text)\n",
    "\n",
    "    # markdown URLs like [Some text](https://....)\n",
    "    text = re.sub(r\"\\[([^\\[\\]]*)\\]\\([^\\(\\)]*\\)\", r\"\\1\", text)\n",
    "\n",
    "    # text or code in brackets like [0]\n",
    "    text = re.sub(r\"\\[[^\\[\\]]*\\]\", \" \", text)\n",
    "\n",
    "    # standalone sequences of specials, matches &# but not #cool\n",
    "    text = re.sub(r\"(?:^|\\s)[&#<>{}\\[\\]+|\\\\:-]{1,}(?:\\s|$)\", \" \", text)\n",
    "\n",
    "    # standalone sequences of hyphens like --- or ==\n",
    "    text = re.sub(r\"(?:^|\\s)[\\-=\\+]{2,}(?:\\s|$)\", \" \", text)\n",
    "\n",
    "    # sequences of white spaces\n",
    "    text = re.sub(r\"\\s+\", \" \", text)\n",
    "\n",
    "    return text.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "premium-dublin",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"After viewing the PINKIEPOOL Trailer it got me thinking about the best match ups. Here's my take: Deadpool Captain America\""
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_text = clean(text)\n",
    "clean_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "smooth-explorer",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Impurity: 0.0\n"
     ]
    }
   ],
   "source": [
    "print(\"Impurity:\", impurity(clean_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "recreational-zambia",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clean_text</th>\n",
       "      <th>impurity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14058</th>\n",
       "      <td>Mustang 2018, 2019, or 2020? Must Haves!! 1. H...</td>\n",
       "      <td>0.030864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18934</th>\n",
       "      <td>At the dealership, they offered an option for ...</td>\n",
       "      <td>0.026455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16505</th>\n",
       "      <td>I am looking at four Caymans, all are in a sim...</td>\n",
       "      <td>0.024631</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              clean_text  impurity\n",
       "14058  Mustang 2018, 2019, or 2020? Must Haves!! 1. H...  0.030864\n",
       "18934  At the dealership, they offered an option for ...  0.026455\n",
       "16505  I am looking at four Caymans, all are in a sim...  0.024631"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"clean_text\"] = df[\"text\"].map(clean)\n",
    "df[\"impurity\"] = df[\"clean_text\"].apply(impurity, min_len=20)\n",
    "df[[\"clean_text\", \"impurity\"]].sort_values(by=\"impurity\", ascending=False).head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "regional-ebony",
   "metadata": {},
   "source": [
    "### Blueprint: Character Normalization with textacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "amateur-exposure",
   "metadata": {},
   "outputs": [],
   "source": [
    "import textacy.preprocessing as tprep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "fifth-public",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(text):\n",
    "    text = tprep.normalize.hyphenated_words(text)\n",
    "    text = tprep.normalize.quotation_marks(text)\n",
    "    text = tprep.normalize.unicode(text)\n",
    "    text = tprep.remove.accents(text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "entitled-devices",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The cafe \"Saint-Raphael\" is located on Cote d\\'Azur.'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"The café “Saint-Raphaël” is loca-\\nted on Côte dʼAzur.\"\n",
    "normalize(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sought-imaging",
   "metadata": {},
   "source": [
    "### Blueprint: Pattern-Based Data Masking with textacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "durable-friend",
   "metadata": {},
   "outputs": [],
   "source": [
    "from textacy.preprocessing.resources import RE_URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "superb-vietnam",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>freq</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>token</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>www.getlowered.com</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>http://www.ecolamautomotive.com/#!2/kv7fq</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>https://www.reddit.com/r/Jeep/comments/4ux232/just_ordered_an_android_head_unit_joying_jeep/</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    freq\n",
       "token                                                   \n",
       "www.getlowered.com                                     3\n",
       "http://www.ecolamautomotive.com/#!2/kv7fq              2\n",
       "https://www.reddit.com/r/Jeep/comments/4ux232/j...     2"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_words(df, column=\"clean_text\", preprocess=RE_URL.findall).head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "extra-modern",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Check out _URL_\n"
     ]
    }
   ],
   "source": [
    "from textacy.preprocessing.replace import urls as replace_urls\n",
    "\n",
    "text = \"Check out https://spacy.io/usage/spacy-101\"\n",
    "print(replace_urls(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "opposed-launch",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"clean_text\"] = df[\"clean_text\"].map(replace_urls)\n",
    "df[\"clean_text\"] = df[\"clean_text\"].map(normalize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "wooden-harris",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rename(columns={\"text\": \"raw_text\", \"clean_text\": \"text\"}, inplace=True)\n",
    "df.drop(columns=[\"impurity\"], inplace=True)\n",
    "\n",
    "con = sqlite3.connect(db_name)\n",
    "df.to_sql(\"posts_cleaned\", con, index=False, if_exists=\"replace\")\n",
    "con.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "signal-circulation",
   "metadata": {},
   "source": [
    "## Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "recorded-brighton",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"2019-08-10 23:32: @pete/@louis - I don't have a well-designed solution for today's problem. The code of module AC68 should be -1. Have to think a bit... #goodnight ;-) 😩😬\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stuffed-fleece",
   "metadata": {},
   "source": [
    "### Blueprint: Tokenization with Regular Expression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "dimensional-express",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019|08|10|23|32|pete|louis|don|have|well|designed|solution|for|today|problem|The|code|of|module|AC68|should|be|Have|to|think|bit|goodnight\n"
     ]
    }
   ],
   "source": [
    "tokens = re.findall(r\"\\w\\w+\", text)\n",
    "print(*tokens, sep=\"|\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "natural-entry",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-08-10|23:32|@pete|@louis|I|don't|have|a|well-designed|solution|for|today's|problem|The|code|of|module|AC68|should|be|-1|Have|to|think|a|bit|#goodnight|;-)|😩|😬\n"
     ]
    }
   ],
   "source": [
    "RE_TOKEN = re.compile(\n",
    "    r\"\"\"\n",
    "               ( [#]?[@\\w'’\\.\\-\\:]*\\w     # words, hash tags and email adresses\n",
    "               | [:;<]\\-?[\\)\\(3]          # coarse pattern for basic text emojis\n",
    "               | [\\U0001F100-\\U0001FFFF]  # coarse code range for unicode emojis\n",
    "               )\n",
    "               \"\"\",\n",
    "    re.VERBOSE,\n",
    ")\n",
    "\n",
    "\n",
    "def tokenize(text):\n",
    "    return RE_TOKEN.findall(text)\n",
    "\n",
    "\n",
    "tokens = tokenize(text)\n",
    "print(*tokens, sep=\"|\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "minor-cabinet",
   "metadata": {},
   "source": [
    "### Tokenization with NLTK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "senior-choice",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-08-10|23:32|:|@|pete/|@|louis|-|I|do|n't|have|a|well-designed|solution|for|today|'s|problem|.|The|code|of|module|AC68|should|be|-1|.|Have|to|think|a|bit|...|#|goodnight|;|-|)|😩😬\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "tokens = nltk.tokenize.word_tokenize(text)\n",
    "print(*tokens, sep=\"|\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "artistic-prison",
   "metadata": {},
   "source": [
    "### Linguistic Processing with spaCy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "collaborative-helmet",
   "metadata": {},
   "source": [
    "**Instantiating a Pipeline**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "yellow-retailer",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "nlp.pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "foster-swing",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('tok2vec', <spacy.pipeline.tok2vec.Tok2Vec at 0x131a6bdb0>),\n",
       " ('tagger', <spacy.pipeline.tagger.Tagger at 0x1338876d0>),\n",
       " ('attribute_ruler',\n",
       "  <spacy.pipeline.attributeruler.AttributeRuler at 0x1317f4c40>),\n",
       " ('lemmatizer', <spacy.lang.en.lemmatizer.EnglishLemmatizer at 0x13169f580>)]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\", disable=[\"parser\", \"ner\"])\n",
    "nlp.pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "executed-october",
   "metadata": {},
   "source": [
    "**Processing Text**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "cordless-thanksgiving",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "text = \"My best friend Ryan Peters likes fancy adventure games.\"\n",
    "doc = nlp(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "supreme-declaration",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My|best|friend|Ryan|Peters|likes|fancy|adventure|games|.|"
     ]
    }
   ],
   "source": [
    "for token in doc:\n",
    "    print(token, end=\"|\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "worth-platinum",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To see a list of attributes created by spaCy on the token.\n",
    "# help(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "impaired-resource",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_nlp(doc, include_punct=False):\n",
    "    \"\"\"Generate data frame for visualization of spaCy tokens.\"\"\"\n",
    "    rows = []\n",
    "    for i, t in enumerate(doc):\n",
    "        if not t.is_punct or include_punct:\n",
    "            row = {\n",
    "                \"token\": i,\n",
    "                \"text\": t.text,\n",
    "                \"lemma_\": t.lemma_,\n",
    "                \"is_stop\": t.is_stop,\n",
    "                \"is_alpha\": t.is_alpha,\n",
    "                \"pos_\": t.pos_,\n",
    "                \"dep_\": t.dep_,\n",
    "                \"ent_type_\": t.ent_type_,\n",
    "                \"ent_iob_\": t.ent_iob_,\n",
    "            }\n",
    "            rows.append(row)\n",
    "\n",
    "    df = pd.DataFrame(rows).set_index(\"token\")\n",
    "    df.index.name = None\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "formal-acrylic",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>lemma_</th>\n",
       "      <th>is_stop</th>\n",
       "      <th>is_alpha</th>\n",
       "      <th>pos_</th>\n",
       "      <th>dep_</th>\n",
       "      <th>ent_type_</th>\n",
       "      <th>ent_iob_</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>My</td>\n",
       "      <td>my</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>PRON</td>\n",
       "      <td>poss</td>\n",
       "      <td></td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>best</td>\n",
       "      <td>good</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>ADJ</td>\n",
       "      <td>amod</td>\n",
       "      <td></td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>friend</td>\n",
       "      <td>friend</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>nsubj</td>\n",
       "      <td></td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ryan</td>\n",
       "      <td>Ryan</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>compound</td>\n",
       "      <td>PERSON</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Peters</td>\n",
       "      <td>Peters</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>appos</td>\n",
       "      <td>PERSON</td>\n",
       "      <td>I</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>likes</td>\n",
       "      <td>like</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>VERB</td>\n",
       "      <td>ROOT</td>\n",
       "      <td></td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>fancy</td>\n",
       "      <td>fancy</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>ADJ</td>\n",
       "      <td>amod</td>\n",
       "      <td></td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>adventure</td>\n",
       "      <td>adventure</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>compound</td>\n",
       "      <td></td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>games</td>\n",
       "      <td>game</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>dobj</td>\n",
       "      <td></td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        text     lemma_  is_stop  is_alpha   pos_      dep_ ent_type_ ent_iob_\n",
       "0         My         my     True      True   PRON      poss                  O\n",
       "1       best       good    False      True    ADJ      amod                  O\n",
       "2     friend     friend    False      True   NOUN     nsubj                  O\n",
       "3       Ryan       Ryan    False      True  PROPN  compound    PERSON        B\n",
       "4     Peters     Peters    False      True  PROPN     appos    PERSON        I\n",
       "5      likes       like    False      True   VERB      ROOT                  O\n",
       "6      fancy      fancy    False      True    ADJ      amod                  O\n",
       "7  adventure  adventure    False      True   NOUN  compound                  O\n",
       "8      games       game    False      True   NOUN      dobj                  O"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "display_nlp(doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "subject-belfast",
   "metadata": {},
   "source": [
    "### Blueprint: Customizing Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "valid-trail",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@Pete|:|choose|low|-|carb|#|food|#|eat|-|smart|.|_|url|_|;-)|"
     ]
    }
   ],
   "source": [
    "text = \"@Pete: choose low-carb #food #eat-smart. _url_ ;-)\"\n",
    "doc = nlp(text)\n",
    "for token in doc:\n",
    "    print(token, end=\"|\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "introductory-remark",
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.tokenizer import Tokenizer\n",
    "from spacy.util import compile_infix_regex, compile_prefix_regex, compile_suffix_regex\n",
    "\n",
    "\n",
    "def custom_tokenizer(nlp):\n",
    "    # Use default patterns except the ones matched by re.search.\n",
    "    prefixes = [\n",
    "        pattern for pattern in nlp.Defaults.prefixes if pattern not in [\"-\", \"_\", \"#\"]\n",
    "    ]\n",
    "    suffixes = [pattern for pattern in nlp.Defaults.suffixes if pattern not in [\"_\"]]\n",
    "    infixes = [\n",
    "        pattern for pattern in nlp.Defaults.infixes if not re.search(pattern, \"xx-xx\")\n",
    "    ]\n",
    "\n",
    "    return Tokenizer(\n",
    "        vocab=nlp.vocab,\n",
    "        rules=nlp.Defaults.tokenizer_exceptions,\n",
    "        prefix_search=compile_prefix_regex(prefixes).search,\n",
    "        suffix_search=compile_suffix_regex(suffixes).search,\n",
    "        infix_finditer=compile_infix_regex(infixes).finditer,\n",
    "        token_match=nlp.Defaults.token_match,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "knowing-nothing",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@Pete|:|choose|low-carb|#food|#eat-smart|.|_url_|;-)|"
     ]
    }
   ],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "nlp.tokenizer = custom_tokenizer(nlp)\n",
    "\n",
    "doc = nlp(text)\n",
    "for token in doc:\n",
    "    print(token, end=\"|\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "atlantic-stevens",
   "metadata": {},
   "source": [
    "### Blueprint: Working with Stop Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "amateur-marketplace",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Dear, Ryan, need, sit, talk, Regards, Pete]\n"
     ]
    }
   ],
   "source": [
    "text = \"Dear Ryan, we need to sit down and talk. Regards, Pete\"\n",
    "doc = nlp(text)\n",
    "\n",
    "non_stop = [t for t in doc if not t.is_stop and not t.is_punct]\n",
    "print(non_stop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "lesbian-vermont",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Ryan, need, sit, down, talk, Pete]\n"
     ]
    }
   ],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "nlp.vocab[\"down\"].is_stop = False\n",
    "nlp.vocab[\"Dear\"].is_stop = True\n",
    "nlp.vocab[\"Regards\"].is_stop = True\n",
    "\n",
    "doc = nlp(text)\n",
    "\n",
    "non_stop = [t for t in doc if not t.is_stop and not t.is_punct]\n",
    "print(non_stop)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "outdoor-castle",
   "metadata": {},
   "source": [
    "### Blueprint: Extracting Lemmas Based on Part of Speech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "perceived-springfield",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "my|good|friend|Ryan|Peters|like|fancy|adventure|game|.\n"
     ]
    }
   ],
   "source": [
    "text = \"My best friend Ryan Peters likes fancy adventure games.\"\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "doc = nlp(text)\n",
    "\n",
    "print(*[t.lemma_ for t in doc], sep=\"|\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "muslim-builder",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[friend, Ryan, Peters, adventure, games]"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nouns = [t for t in doc if t.pos_ in [\"NOUN\", \"PROPN\"]]\n",
    "nouns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "russian-collect",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best|friend|fancy|adventure|games\n"
     ]
    }
   ],
   "source": [
    "import textacy\n",
    "\n",
    "tokens = textacy.extract.words(\n",
    "    doc,\n",
    "    filter_stops=True,  # Default True, no stopwords.\n",
    "    filter_punct=True,  # Default True, no punctuation.\n",
    "    filter_nums=True,  # Default False, no numbers.\n",
    "    include_pos=[\"ADJ\", \"NOUN\"],  # Default None = include all\n",
    "    exclude_pos=None,  # Default None = exclude none,\n",
    "    min_freq=1,  # Minimum frequency of words.\n",
    ")\n",
    "print(*[t for t in tokens], sep=\"|\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "dated-occupation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "good|friend|fancy|adventure|game\n"
     ]
    }
   ],
   "source": [
    "def extract_lemmas(doc, **kwargs):\n",
    "    return [t.lemma_ for t in textacy.extract.words(doc, **kwargs)]\n",
    "\n",
    "\n",
    "lemmas = extract_lemmas(doc, include_pos=[\"ADJ\", \"NOUN\"])\n",
    "print(*lemmas, sep=\"|\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "black-pressure",
   "metadata": {},
   "source": [
    "### Blueprint: Extracting Noun Phrases\n",
    "\n",
    "The pattern below extracts sequences of nouns with a preceding adjectives."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "patient-librarian",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "good friend|fancy adventure|fancy adventure game\n"
     ]
    }
   ],
   "source": [
    "text = \"My best friend Ryan Peters likes fancy adventure games.\"\n",
    "doc = nlp(text)\n",
    "\n",
    "patterns = [\"POS:ADJ POS:NOUN:+\"]\n",
    "spans = textacy.extract.token_matches(doc, patterns=patterns)\n",
    "print(*[s.lemma_ for s in spans], sep=\"|\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "painful-night",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My best friend|Ryan Peters|fancy adventure games\n"
     ]
    }
   ],
   "source": [
    "print(*doc.noun_chunks, sep=\"|\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "voluntary-acrylic",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_noun_phrases(doc, preceding_pos=[\"NOUN\"], sep=\"_\"):\n",
    "    patterns = []\n",
    "    for pos in preceding_pos:\n",
    "        patterns.append(f\"POS:{pos} POS:NOUN:+\")\n",
    "    spans = textacy.extract.token_matches(doc, patterns=patterns)\n",
    "    return [sep.join([t.lemma_ for t in s]) for s in spans]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "searching-magnitude",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "good_friend|fancy_adventure|fancy_adventure_game|adventure_game\n"
     ]
    }
   ],
   "source": [
    "print(*extract_noun_phrases(doc, [\"ADJ\", \"NOUN\"]), sep=\"|\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pharmaceutical-worst",
   "metadata": {},
   "source": [
    "### Blueprint: Extracting Named Entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "korean-network",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(James O'Neill, PERSON) (World Cargo Inc, ORG) (San Francisco, GPE) "
     ]
    }
   ],
   "source": [
    "text = \"James O'Neill, chairman of World Cargo Inc, lives in San Francisco.\"\n",
    "\n",
    "doc = nlp(text)\n",
    "for ent in doc.ents:\n",
    "    print(f\"({ent.text}, {ent.label_})\", end=\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "saved-width",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">\n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    James O'Neill\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       ", chairman of \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    World Cargo Inc\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       ", lives in \n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    San Francisco\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       ".</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from spacy import displacy\n",
    "\n",
    "displacy.render(doc, style=\"ent\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "extraordinary-suite",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"James_O'Neill/PERSON\", 'San_Francisco/GPE']"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def extract_entities(doc, include_types=None, sep=\"_\"):\n",
    "    ents = textacy.extract.entities(\n",
    "        doc,\n",
    "        include_types=include_types,\n",
    "        exclude_types=None,\n",
    "        drop_determiners=True,\n",
    "        min_freq=1,\n",
    "    )\n",
    "\n",
    "    return [sep.join([t.lemma_ for t in e]) + \"/\" + e.label_ for e in ents]\n",
    "\n",
    "\n",
    "extract_entities(doc, [\"PERSON\", \"GPE\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "after-salon",
   "metadata": {},
   "source": [
    "## Feature Extraction on Large Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "native-clinton",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_nlp(doc):\n",
    "    return {\n",
    "        \"lemmas\": extract_lemmas(\n",
    "            doc,\n",
    "            exclude_pos=[\"PART\", \"PUNCT\", \"DET\", \"PRON\", \"SYM\", \"SPACE\"],\n",
    "            filter_stops=False,\n",
    "        ),\n",
    "        \"adjs_verbs\": extract_lemmas(doc, include_pos=[\"ADJ\", \"VERB\"]),\n",
    "        \"nouns\": extract_lemmas(doc, include_pos=[\"NOUN\", \"PROPN\"]),\n",
    "        \"noun_phrases\": extract_noun_phrases(doc, [\"NOUN\"]),\n",
    "        \"adj_noun_phrases\": extract_noun_phrases(doc, [\"ADJ\"]),\n",
    "        \"entities\": extract_entities(doc, [\"PERSON\", \"ORG\", \"GPE\", \"LOC\"]),\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "earned-worst",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lemmas: ['good', 'friend', 'Ryan', 'Peters', 'like', 'fancy', 'adventure', 'game']\n",
      "adjs_verbs: ['good', 'like', 'fancy']\n",
      "nouns: ['friend', 'Ryan', 'Peters', 'adventure', 'game']\n",
      "noun_phrases: ['adventure_game']\n",
      "adj_noun_phrases: ['good_friend', 'fancy_adventure', 'fancy_adventure_game']\n",
      "entities: ['Ryan_Peters/PERSON']\n"
     ]
    }
   ],
   "source": [
    "text = \"My best friend Ryan Peters likes fancy adventure games.\"\n",
    "doc = nlp(text)\n",
    "\n",
    "for col, values in extract_nlp(doc).items():\n",
    "    print(f\"{col}: {values}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "younger-trace",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['lemmas',\n",
       " 'adjs_verbs',\n",
       " 'nouns',\n",
       " 'noun_phrases',\n",
       " 'adj_noun_phrases',\n",
       " 'entities']"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp_columns = list(extract_nlp(nlp.make_doc(\"\")).keys())\n",
    "nlp_columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "interim-scholar",
   "metadata": {},
   "source": [
    "### Blueprint: Using spaCy on a Large Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "alleged-belfast",
   "metadata": {},
   "outputs": [],
   "source": [
    "db_name = \"data/reddit-selfposts.db\"\n",
    "con = sqlite3.connect(db_name)\n",
    "df = pd.read_sql(\"select * from posts_cleaned\", con)\n",
    "con.close()\n",
    "\n",
    "df[\"text\"] = df[\"title\"] + \": \" + df[\"text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "laughing-research",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize new DataFrame columns.\n",
    "for col in nlp_columns:\n",
    "    df[col] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "together-curtis",
   "metadata": {},
   "outputs": [],
   "source": [
    "if spacy.prefer_gpu():\n",
    "    print(\"Working on GPU.\")\n",
    "else:\n",
    "    print(\"No GPU found, working on CPU.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "freelance-horizon",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sample(500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "thorough-manner",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 400/400 [06:58<00:00,  1.05s/it]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\", disable=[])\n",
    "nlp.tokenizer = custom_tokenizer(nlp)\n",
    "\n",
    "batch_size = 50\n",
    "\n",
    "for i in tqdm(range(0, len(df), batch_size)):\n",
    "    docs = nlp.pipe(df[\"text\"][i : i + batch_size])\n",
    "    for j, doc in enumerate(docs):\n",
    "        for col, values in extract_nlp(doc).items():\n",
    "            df[col].iloc[i + j] = values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "compact-heading",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "count_words(df, \"noun_phrases\").head(10).plot(kind=\"barh\").invert_yaxis()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "average-celebration",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[nlp_columns] = df[nlp_columns].applymap(lambda items: \" \".join(items))\n",
    "\n",
    "con = sqlite3.connect(db_name)\n",
    "df.to_sql(\"posts_nlp\", con, index=False, if_exists=\"replace\")\n",
    "con.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
